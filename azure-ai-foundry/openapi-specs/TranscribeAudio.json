{
  "openapi": "3.0.3",
  "info": {
    "title": "Transcribe Audio Action",
    "description": "Transcribes audio to text using local Whisper (default) with Azure Speech-to-Text fallback.\n\nThis action processes audio files using OpenAI Whisper for accurate, local transcription with automatic fallback to Azure Speech Services. Supports quality settings, language detection/override, and service selection. Automatically cleans up audio files after successful transcription.\n\nPerfect for Azure AI Foundry workflows that need high-quality, cost-effective speech-to-text conversion with local processing capabilities.",
    "version": "2.0.0-stateless",
    "contact": {
      "name": "Andy Cohen",
      "email": "andy@iamandycohen.com"
    },
    "license": {
      "name": "MIT",
      "url": "https://opensource.org/licenses/MIT"
    }
  },
  "servers": [
    {
      "url": "https://video-transcribe-api.calmocean-ce622c12.eastus2.azurecontainerapps.io",
      "description": "Production API server"
    }
  ],
  "paths": {
    "/transcribe-audio": {
      "post": {
        "summary": "Start Audio Transcription Job",
        "description": "Starts a background job to transcribe audio to text using local Whisper (default) with Azure Speech-to-Text fallback.\n\nReturns immediately with a job_id for monitoring progress. Uses OpenAI Whisper for local, cost-effective transcription with automatic model downloads. Falls back to Azure Speech Services if Whisper fails. Supports quality settings (fast/balanced/accurate/best), language detection/override, and service selection.\n\nAutomatically cleans up audio file after successful transcription. Stores raw_text in workflow state for enhancement and analysis.\n\nJob-Based Workflow:\n1. Extract audio using extract_audio action → get job_id, poll until complete\n2. Call this action with workflow_id and optional parameters → get new job_id\n3. Poll GET /jobs/{job_id} every 2-5 seconds until completion\n4. Use same workflow_id with text processing actions",
        "operationId": "transcribe_audio",
        "tags": ["File Processing"],
        "requestBody": {
          "required": true,
          "content": {
            "application/json": {
                "schema": {
                  "type": "object",
                  "required": ["workflow_id"],
                  "properties": {
                    "workflow_id": {
                      "type": "string",
                      "description": "Workflow identifier - must have extracted audio",
                      "example": "6902573c-9c6c-446c-9f32-72bf5e5554f6"
                    },
                    "quality": {
                      "type": "string",
                      "enum": ["fast", "balanced", "accurate", "best"],
                      "description": "Transcription quality setting. Maps to Whisper models: fast=tiny, balanced=base, accurate=small, best=medium",
                      "default": "balanced",
                      "example": "balanced"
                    },
                    "language": {
                      "type": "string",
                      "description": "Language code for transcription (e.g., 'en', 'es', 'fr'). If not provided, language will be auto-detected",
                      "example": "en"
                    },
                    "use_azure": {
                      "type": "boolean",
                      "description": "Force use of Azure Speech Services instead of local Whisper. Default is false (Whisper preferred)",
                      "default": false,
                      "example": false
                    }
                  }
                }
            }
          }
        },
        "responses": {
          "202": {
            "description": "Audio transcription job started successfully",
            "content": {
              "application/json": {
                "schema": {
                  "type": "object",
                  "properties": {
                    "success": {
                      "type": "boolean",
                      "example": true
                    },
                    "job_id": {
                      "type": "string",
                      "description": "Job identifier for polling progress and results",
                      "example": "job_xyz789abc123"
                    },
                    "status": {
                      "type": "string",
                      "enum": ["queued"],
                      "description": "Initial job status",
                      "example": "queued"
                    },
                    "progress": {
                      "type": "number",
                      "minimum": 0,
                      "maximum": 100,
                      "description": "Initial progress percentage",
                      "example": 0
                    },
                    "message": {
                      "type": "string",
                      "description": "Human-readable status message",
                      "example": "Audio transcription job started"
                    },
                    "workflow_id": {
                      "type": "string",
                      "description": "Workflow identifier for subsequent operations",
                      "example": "6902573c-9c6c-446c-9f32-72bf5e5554f6"
                    },
                    "next_action": {
                      "type": "string",
                      "description": "Instructions for polling job status",
                      "example": "Poll GET /jobs/job_xyz789abc123 every 2-5 seconds for progress and completion"
                    }
                  },
                  "required": ["success", "job_id", "status", "progress", "message", "workflow_id", "next_action"]
                }
              }
            }
          },
          "400": {
            "description": "Bad request - invalid workflow_id or no audio",
            "content": {
              "application/json": {
                "schema": {
                  "type": "object",
                  "properties": {
                    "success": {
                      "type": "boolean",
                      "example": false
                    },
                    "error": {
                      "type": "string",
                      "examples": [
                        "workflow_id is required",
                        "Workflow not found",
                        "No audio found in workflow"
                      ]
                    },
                    "timestamp": {
                      "type": "string",
                      "format": "date-time"
                    }
                  }
                }
              }
            }
          },
          "401": {
            "description": "Unauthorized - authentication required",
            "content": {
              "application/json": {
                "schema": {
                  "type": "object",
                  "properties": {
                    "success": {
                      "type": "boolean",
                      "example": false
                    },
                    "error": {
                      "type": "string",
                      "example": "Unauthorized - Valid authentication required"
                    }
                  }
                }
              }
            }
          },
          "500": {
            "description": "Internal server error",
            "content": {
              "application/json": {
                "schema": {
                  "type": "object",
                  "properties": {
                    "success": {
                      "type": "boolean",
                      "example": false
                    },
                    "error": {
                      "type": "string",
                      "example": "Transcription failed"
                    },
                    "timestamp": {
                      "type": "string",
                      "format": "date-time"
                    }
                  }
                }
              }
            }
          }
        },
        "security": [
          {
            "ApiKeyAuth": []
          },
          {
            "AzureManagedIdentity": []
          }
        ]
      }
    }
  },
  "components": {
    "securitySchemes": {
      "ApiKeyAuth": {
        "type": "apiKey",
        "in": "header",
        "name": "X-API-Key",
        "description": "API key for direct REST API access"
      },
      "AzureManagedIdentity": {
        "type": "http",
        "scheme": "bearer",
        "description": "Azure Managed Identity token (automatically handled by Azure AI Foundry)"
      }
    }
  },
  "tags": [
    {
      "name": "File Processing",
      "description": "Video and audio processing operations"
    }
  ]
}
