# Video Transcribe Agent

A multi-package TypeScript solution for transcribing MP4 video files using Azure AI services. Available as a **core library**, **CLI tool**, and **API server** for maximum flexibility in AI agent architectures.

## Features

- üé• **MP4 Audio Extraction**: Automatically extracts audio from MP4 video files
- üé§ **High-Quality Transcription**: Uses local Whisper (default) with Azure Speech-to-Text fallback
- ü§ñ **AI Enhancement**: Optional GPT-powered transcription improvement and analysis
- üìù **Multiple Output Formats**: Supports JSON and text output formats
- üîç **Rich Analysis**: Generates summaries, key points, topics, and sentiment analysis
- üè• **Health Monitoring**: Built-in status checks for all services
- üìä **Detailed Logging**: Comprehensive logging with configurable levels
- üîó **Agent Integration**: Ready-to-use with LangChain, AutoGen, CrewAI, and other agent frameworks
- üåê **API Server Mode**: HTTP API for multi-agent architectures
- ü§ñ **Autonomous Mode**: Self-running agent that monitors directories and processes videos automatically
- ‚ö° **Step-Based Workflow Tracking**: Advanced workflow state management with detailed step status, timing, and error tracking
- üîÑ **Individual Step Retry**: Retry failed steps without restarting entire workflows
- üéØ **Modular Architecture**: Organized workflow steps (processing vs analysis) for easy maintenance and extension

### üéß Whisper Integration

- üÜì **Local Processing**: Free, offline transcription using OpenAI Whisper
- üèÉ **Quality Levels**: `fast` (tiny), `balanced` (base), `accurate` (small), `best` (medium) models
- üåç **Multi-Language**: Auto-detection or manual language override support
- üì¶ **Auto-Download**: Models download automatically on first use
- üîÑ **Smart Fallback**: Automatic fallback to Azure Speech Services if Whisper fails
- üí∞ **Cost-Effective**: Reduce Azure Speech Services usage while maintaining quality

## Prerequisites

- Node.js 18.0.0 or higher
- FFmpeg (included via ffmpeg-static package)
- Azure subscription with AI services (optional - only needed for AI enhancement and cloud transcription)

## üì¶ Package Structure

This monorepo contains three main packages:

- **`@video-transcribe/core`** - Core library for programmatic usage
- **`@video-transcribe/cli`** - Command-line interface
- **`@video-transcribe/server`** - REST API server

## Installation

### üöÄ For Library Usage

```bash
npm install @video-transcribe/core
```

### üõ†Ô∏è For Development/Contribution

1. Clone the repository:
```bash
git clone <repository-url>
cd video-transcribe
```

2. Install workspace dependencies:
```bash
npm install
```

3. Build all packages:
```bash
npm run build
```

4. Configure environment:
```bash
# Create .env.local with your Azure configuration
# See env-config-template.txt for required variables
```

## Configuration

The application can work in two modes:

### Local Mode (Whisper Only)
- **Local Whisper**: Free offline transcription (default)
- **No Azure required**: Works completely offline for basic transcription
- Only needs `API_KEY` for CLI/API access

### Enhanced Mode (with Azure Services)
- **Azure Speech Services**: For cloud transcription fallback
- **Azure OpenAI**: For transcription enhancement and analysis
- **Azure AI Foundry**: For project management and agent integration

Create a `.env.local` file with your configuration:
```bash
# Required for any mode
API_KEY=your-secure-api-key

# Required only for Azure features
AZURE_SUBSCRIPTION_ID=your-subscription-id
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
# ... other Azure variables
```

See `.env.example` for the complete configuration template. The application includes configuration validation that will fail fast if required variables are missing.

## Usage

### Agent Integration

The transcription agent can be integrated into larger AI agent systems in multiple ways:

#### 1. Main Agent Class (Recommended)
```typescript
import { TranscriptionAgent } from '@video-transcribe/core';

const agent = new TranscriptionAgent();

// Basic transcription with Whisper (default)
const result = await agent.processVideo({
  inputFile: './meeting.mp4',
  enhanceWithGPT: true,
  format: 'both'
});

// Custom Whisper options
const result = await agent.transcribeVideo({
  videoPath: './meeting.mp4',
  enhance: true,
  outputFormat: 'json',
  whisperOptions: {
    quality: 'accurate',  // tiny, base, small, medium
    language: 'en',       // optional language override
    useAzure: false       // false = Whisper (default), true = Azure
  }
});

// Force Azure Speech Services
const result = await agent.transcribeVideo({
  videoPath: './meeting.mp4',
  useAzure: true,
  enhance: true
});
```

#### 2. Atomic Services (Advanced)
```typescript
import { ServiceManager } from '@video-transcribe/core';

const services = ServiceManager.getInstance();
const workflowId = await services.getAgentStateStore().createWorkflow();
// Full control over individual steps...
```

#### 3. API Server Mode
```bash
# Start the API server
node packages/server/dist/server.js

# Job-based workflow example
# 1. Create workflow
curl -X POST http://localhost:3000/workflow \
  -H "Content-Type: application/json" \
  -H "x-api-key: YOUR_API_KEY"

# 2. Upload video (returns job_id)
curl -X POST http://localhost:3000/upload-video \
  -H "Content-Type: application/json" \
  -H "x-api-key: YOUR_API_KEY" \
  -d '{"workflow_id": "abc123", "source_url": "https://example.com/video.mp4"}'

# 3. Poll job status until completion
curl -X GET http://localhost:3000/jobs/job_xyz789 \
  -H "x-api-key: YOUR_API_KEY"

# 4. Continue with next step using workflow_id
```

#### 4. Autonomous Agent
```typescript
import { AutonomousVideoAgent } from './examples/autonomous-agent';

const agent = new AutonomousVideoAgent();
agent.addWatchPath('./incoming-videos');
await agent.start(); // Monitors and processes automatically
```

#### 5. Framework-Specific Integration
- **LangChain**: See `examples/langchain-agent.ts`
- **AutoGen**: See `examples/autogen-agent.py`
- **CrewAI**: See `examples/crewai-agent.py`
- **Custom**: See `examples/integration-guide.md`

### üéß Whisper Usage Guide

#### Quality Levels
```bash
# Model sizes and performance characteristics:
--whisper-quality fast     # tiny model   (~39MB)  - fastest, basic quality
--whisper-quality balanced # base model   (~74MB)  - good speed/quality balance  
--whisper-quality accurate # small model  (~244MB) - higher accuracy
--whisper-quality best     # medium model (~769MB) - highest quality
```

#### Language Support
```bash
# Auto-detection (default)
video-transcribe transcribe video.mp4

# Specific language (improves accuracy)
video-transcribe transcribe video.mp4 --language en    # English
video-transcribe transcribe video.mp4 --language es    # Spanish  
video-transcribe transcribe video.mp4 --language fr    # French
video-transcribe transcribe video.mp4 --language de    # German
video-transcribe transcribe video.mp4 --language zh    # Chinese
# ... supports 100+ languages
```

#### Model Management
- **Automatic Downloads**: Models download on first use
- **Caching**: Models cached in system directory
- **Offline**: Works completely offline after first download
- **Fallback**: Auto-fallback to Azure if Whisper fails

#### Performance Tips
- Use `fast` for quick drafts or real-time processing
- Use `balanced` for most production use cases (default)
- Use `accurate` for important content requiring precision
- Use `best` for critical transcriptions where quality is paramount
- Set `WHISPER_SUPPRESS_WARNINGS=true` to reduce console noise

### üñ•Ô∏è CLI Usage

#### Install CLI Globally
```bash
npm install -g @video-transcribe/cli
```

#### Basic Commands
```bash
# Transcribe a video (uses Whisper by default, enhanced)
video-transcribe transcribe video.mp4

# Basic transcription without enhancement  
video-transcribe transcribe video.mp4 --enhance false

# Custom output directory and format
video-transcribe transcribe video.mp4 -o ./my-output --format txt

# Whisper quality levels
video-transcribe transcribe video.mp4 --whisper-quality fast     # tiny model, fastest
video-transcribe transcribe video.mp4 --whisper-quality balanced # base model, default  
video-transcribe transcribe video.mp4 --whisper-quality accurate # small model, more accurate
video-transcribe transcribe video.mp4 --whisper-quality best     # medium model, highest quality

# Language override (auto-detected if not specified)
video-transcribe transcribe video.mp4 --language en
video-transcribe transcribe video.mp4 --language es

# Force Azure Speech Services instead of Whisper
video-transcribe transcribe video.mp4 --use-azure

# Resume a workflow from a specific step
video-transcribe resume <workflow-id>
video-transcribe resume <workflow-id> --from-step transcribe

# Check service health
video-transcribe status

# View configuration
video-transcribe config
```

### üåê API Server Usage

#### Start Server
```bash
# Install server package
npm install -g @video-transcribe/server

# Start server
video-transcribe-server
```

#### API Endpoints

**Job-Based Operations (return job_id, require polling):**
- `POST /upload-video` - Download video from URL (returns job_id)
- `POST /extract-audio` - Extract audio from video (returns job_id)
- `POST /transcribe-audio` - Transcribe audio to text using Whisper/Azure (returns job_id)
- `POST /enhance-transcription` - Enhance transcription with GPT (returns job_id)

**Job Management:**
- `GET /jobs/{job_id}` - Poll job status, progress, and results
- `POST /jobs/{job_id}/cancel` - Cancel running or queued jobs

**Quick Operations (immediate response):**
- `POST /workflow` - Create a new workflow
- `POST /summarize-content` - Generate content summary
- `POST /extract-key-points` - Extract key points
- `POST /analyze-sentiment` - Analyze sentiment
- `POST /identify-topics` - Identify topics
- `GET /workflow/:id` - Get workflow status
- `GET /health` - Health check

#### Transcribe Audio Options
```json
{
  "workflow_id": "uuid",
  "quality": "fast|balanced|accurate|best",
  "language": "en|es|fr|...",
  "use_azure": false
}
```


## üõ†Ô∏è Development & Build Commands

```bash
# Build all packages
npm run build

# Build individual packages  
npm run build:core
npm run build:cli
npm run build:server

# Clean all builds
npm run clean
```

## Output Formats

### JSON Output
Contains complete transcription data including:
- Raw transcription with segments and timestamps
- Enhanced transcription (if requested)
- Summary and key points
- Topics and sentiment analysis
- Processing metadata

### Text Output
Human-readable format with:
- Enhanced transcription text
- Summary section
- Key points as bullet list

## Architecture

The application uses a **step-based workflow architecture** with modular components:

### Core Components:
- **Workflow State Management**: Advanced step-based tracking with status, timing, and error details
- **Stateless Actions**: Individual atomic operations (upload, extract, transcribe, analyze)
- **Service Layer**: Reusable business logic separate from API concerns
- **Configuration Management**: Environment-based settings for models and endpoints

### Workflow Steps:
- **Processing Steps**: upload-video ‚Üí extract-audio ‚Üí transcribe-audio ‚Üí enhance-transcription
- **Analysis Steps**: summarize-content, extract-key-points, analyze-sentiment, identify-topics

### Key Services:
- **AudioExtractorService**: Handles MP4 audio extraction using FFmpeg
- **TranscriptionService**: Manages Azure Speech-to-Text integration
- **GPTEnhancementService**: Provides AI-powered transcription enhancement
- **AgentStateStore**: Manages workflow state with automatic legacy migration

## Error Handling

The application includes comprehensive error handling:
- Input file validation
- Azure service connectivity checks
- Graceful degradation when enhancement fails
- Detailed error logging and reporting

## Development

### Available Scripts

- `npm run build`: Compile TypeScript
- `npm run start`: Run the compiled application
- `npm run dev`: Run with ts-node for development
- `npm run clean`: Remove compiled files
- `npm run lint`: Run ESLint
- `npm run test`: Run Jest tests
- `npm run test-agent`: Test agent integration patterns
- `npm run api-server`: Start HTTP API server for agents
- `npm run autonomous`: Run autonomous monitoring agent

### Project Structure

```
src/
‚îú‚îÄ‚îÄ actions/            # Stateless API action handlers
‚îú‚îÄ‚îÄ workflow-steps/     # Modular step type definitions
‚îÇ   ‚îú‚îÄ‚îÄ base/          # Common step interfaces
‚îÇ   ‚îú‚îÄ‚îÄ processing/    # Video/audio processing steps
‚îÇ   ‚îî‚îÄ‚îÄ analysis/      # AI analysis steps
‚îú‚îÄ‚îÄ services/          # Core business logic services
‚îú‚îÄ‚îÄ lib/               # Reusable utility libraries
‚îÇ   ‚îú‚îÄ‚îÄ auth/         # Authentication helpers
‚îÇ   ‚îú‚îÄ‚îÄ responses/    # Standardized API responses
‚îÇ   ‚îú‚îÄ‚îÄ storage/      # File upload/cleanup management
‚îÇ   ‚îî‚îÄ‚îÄ validation/   # Input validation utilities
‚îú‚îÄ‚îÄ config/           # Configuration management
‚îú‚îÄ‚îÄ middleware/       # Express middleware
‚îú‚îÄ‚îÄ cli/              # Command-line interface
‚îî‚îÄ‚îÄ utils/            # Utilities (logging, etc.)
```

### Key Folders:
- **`workflow-steps/`**: Type-safe step definitions organized by category
- **`actions/`**: HTTP API endpoints that orchestrate workflow steps
- **`services/`**: Pure TypeScript business logic (reusable across interfaces)
- **`lib/`**: Shared utilities for common patterns

## Deployment to Azure

This application is designed to run on Azure. Consider using:

- **Azure Container Instances** for simple deployment
- **Azure App Service** for web application scenarios
- **Azure Functions** for serverless execution
- **Azure Kubernetes Service** for scalable deployments

## Troubleshooting

### Common Issues

1. **FFmpeg not found**: Ensure ffmpeg-static is properly installed
2. **Azure authentication**: Verify your API keys and endpoints
3. **Large file processing**: Monitor memory usage for very long videos
4. **Network timeouts**: Check Azure service availability

### Logs

Check the `logs/` directory for detailed error information:
- `combined.log`: All log messages
- `error.log`: Error messages only

## License

MIT License - see LICENSE file for details.

## Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

## Support

For issues and questions:
1. Check the troubleshooting section
2. Review the logs for error details
3. Ensure all Azure services are properly configured
4. Create an issue in the repository